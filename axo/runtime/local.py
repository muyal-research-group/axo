"""
axo/runtime/local.py
~~~~~~~~~~~~~~~~~~~~

Concrete **local** implementation of :class:`axo.runtime.runtime.ActiveXRuntime`.

The class spins up:

* a bounded :class:`queue.Queue` used by the global scheduler to enqueue
  :class:`axo.scheduler.Task` objects,
* a minimal :class:`axo.endpoint.LocalEndpoint` for metadata operations, and
* a :class:`axo.storage.data.LocalStorageService` that persists data to the
  local filesystem.

Because everything runs in‑process, no network calls are performed, making
`LocalRuntime` ideal for unit tests or single‑node deployments.
"""

from __future__ import annotations
import os
from typing import TYPE_CHECKING,Dict,Any
from weakref import WeakKeyDictionary
import time as T
from queue import Queue
from threading import Thread
# 
from option import Result,Ok,Err

from axo.core.axo import Axo,axo_method
from axo.endpoint.manager import LocalEndpointManager,EndpointManagerP
from axo.runtime.runtime import ActiveXRuntime
from axo.scheduler import AxoScheduler,Scheduler
from axo.storage.services import StorageService,LocalStorageService
from axo.storage.loader import AxoLoader
from axo.storage import AxoStorage
from axo.log import get_logger
from axo.models import Task
from axo.errors import AxoError,AxoErrorType
from axo.helpers import serialize_blobs_from_instance
# --------------------------------------------------------------------------- #
# Logger (module‑local)
# --------------------------------------------------------------------------- #

logger = get_logger(
    name  = __name__ ,
    ltype = os.environ.get("AXO_LOG_TYPE","json") ,
    debug = os.environ.get("AXO_DEBUG","1")       == "1",
    path  = os.environ.get("AXO_LOG_PATH","/log") ,
)
# logging.getLogger(__name__)


# ============================================================================
# Local runtime
# ============================================================================
class LocalRuntime(ActiveXRuntime,Thread):
    """
    Single‑process runtime: tasks are executed in the current Python interpreter
    without any remote calls.

    Parameters
    ----------
    runtime_id :
        Optional identifier; if empty a nanoid will be generated by the
        :class:`ActiveXRuntime` base‑class.
    maxsize :
        Maximum number of pending tasks in the internal queue.
    storage_service :
        Custom storage backend (useful for dependency injection in tests).
        If ``NONE`` (default) a :class:`LocalStorageService` instance is created.
    """

    def __init__(
        self,
        storage_service: StorageService = LocalStorageService(storage_service_id="local_storage"),
        runtime_id: str = "",
        # is_distributed: bool = False,
        maxsize: int = 100,
        q_tick_s:int = 1,
        loader_api_globals: Dict[str,Any] = {},
        # safe_builtins: dict | None = None,
    ) -> None:
        super().__init__(name=runtime_id,daemon=True)
        self.__runtime_id = runtime_id
        # Shared task queue ------------------------------------------------
        self.__q: Queue = Queue(maxsize=maxsize)

        # Endpoint manager with a single local endpoint --------------------
        self.__endpoint_manager = LocalEndpointManager()
        self.__endpoint_manager.add_endpoint(endpoint_id="axo-endpoint-0")

        # Storage backend (provided or default) ----------------------------
        self.__storage_service: StorageService = storage_service
        self.__axo_storage = AxoStorage(storage=self.__storage_service)
        self.__axo_loader = AxoLoader(
            storage=self.__axo_storage,
            api_globals={**loader_api_globals,"Axo":Axo,"axo_method":axo_method} or {},
            safe_builtins={},
        )
        self.__inmemory_objects = WeakKeyDictionary()
        # .unwrap_or(
            # LocalStorageService(storage_service_id="local-store")
        # )
        self.__is_running = True
        # Scheduler --------------------------------------------------------
        self.__scheduler = AxoScheduler(tasks=[], runtime_queue=self.__q)
        self.__q_tick_s = q_tick_s
        self.start()

 
    @property
    def runtime_id(self):
        return self.__runtime_id
    @property
    def q(self):
        return self.__q
    @property
    def is_distributed(self)->bool:
        return False
    
    @property
    def scheduler(self)->Scheduler:
        return self.__scheduler
    @property
    def storage_service(self)->StorageService:
        return self.__storage_service
    @property
    def endpoint_manager(self)->EndpointManagerP:
        return self.__endpoint_manager
    @property
    def inmemory_objects(self)->WeakKeyDictionary[Axo,None]:
        return self.__inmemory_objects
    @property
    def axo_storage(self) -> AxoStorage: return self.__axo_storage
    @property
    def axo_loader(self) -> AxoLoader: return self.__axo_loader

    @property
    def is_running(self)->bool:
        return self.__is_running  
    async def get_active_object(self, *, bucket_id: str, key: str) -> Result[Axo, AxoError]:
        return await self.__axo_loader.load_object(bucket_id=bucket_id, key=key)


    async def persistify(self, instance: Axo, *, bucket_id: str = "axo", key: str | None = None) -> Result[str, AxoError]:
        try:
            t1 = T.time()
            key = key or instance.get_axo_key()

            # 1) store endpoint metadata (unchanged behavior)
            endpoint = self.__endpoint_manager.get_endpoint(instance.get_endpoint_id())
            if not endpoint:
                return Err(AxoError.make(AxoErrorType.NOT_FOUND, f"No endpoint found: {instance.get_endpoint_id()}"))
            meta_res = endpoint.put(key=key, value=instance._acx_metadata)
            if meta_res.is_err:
                return Err(AxoError.make(AxoErrorType.INTERNAL_ERROR, str(meta_res.unwrap_err())))

            # 2) build blobs + store via AxoStorage
            blobs_res = serialize_blobs_from_instance(instance, bucket_id=bucket_id, key=key)
            if blobs_res.is_err:
                return Err(blobs_res.unwrap_err())
            blobs, class_name = blobs_res.unwrap()

            put_res = await self.__axo_storage.put_blobs(
                bucket_id=bucket_id,
                key=key,
                blobs=blobs,
                class_name=class_name,
            )
            if put_res.is_err:
                return Err(put_res.unwrap_err())

            logger.info({
                "event": "PERSISTIFY",
                "mode": "LOCAL",
                "bucket_id": bucket_id,
                "key": key,
                "response_time":T.time() - t1
            })
            return Ok(key)
        except AxoError as ax:
            return Err(ax)
        except Exception as e:
            return Err(AxoError.make(AxoErrorType.INTERNAL_ERROR, f"persistify failed: {e}"))

        # return super().persistify(instance, bucket_id=bucket_id, key=key)
    def _handle_put_task(self, task):
        return super()._handle_put_task(task)
    def run(self):
        """Main consumer loop."""
        while self.is_running:
            task: Task = self.q.get()
            if T.time() < task.executes_at:
                self.q.put(task)
                # continue
            elif task.operation == "PUT":
                self._handle_put_task(task)
            elif task.operation == "DROP":
                logger.debug("DROP not implemented (%s)", task.id)
            T.sleep(self.__q_tick_s)
            

    # ------------------------------------------------------------------ #
    # Runtime control
    # ------------------------------------------------------------------ #
    def stop(self) -> None:
        """Gracefully stop the background thread."""
        logger.debug("Stopping LocalRuntime %s …", self.name)
        self.__is_running = False
